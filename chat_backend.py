"""
Flask backend for Gemini consultation chatbot
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from google import genai

app = Flask(__name__)
CORS(app)

# ==== HARDCODED API KEY (as you requested) ====
GEMINI_API_KEY = "AIzaSyCVfYG8HFdh_Os8pWuzbLDH-J-r75V67sk"
client = genai.Client(api_key=GEMINI_API_KEY)


# ---------- Helper: Gemini with model fallback ----------

def generate_with_fallback(prompt: str):
    """Try multiple Gemini models until one works."""
    models_to_try = [
        'gemini-2.5-flash',
        'gemini-2.0-flash',
        'gemini-2.0-flash-001',
        'gemini-2.5-pro',
        'gemini-2.0-pro-exp'
    ]

    last_error = None
    for model_name in models_to_try:
        try:
            print(f"[DEBUG] Trying model: {model_name}")
            response = client.models.generate_content(
                model=model_name,
                contents=prompt
            )
            print(f"[DEBUG] Success with {model_name}, response length: {len(response.text)}")
            return {
                'success': True,
                'response': response.text,
                'model_used': model_name
            }
        except Exception as e:
            error_msg = str(e)
            print(f"[DEBUG] Model {model_name} failed: {error_msg[:120]}")
            last_error = error_msg
            continue

    return {
        'success': False,
        'error': f'All models failed. Last error: {last_error}'
    }


# ---------- Health check ----------

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy', 'service': 'Gemini Consultation Backend'})


# ---------- OPTIONAL: keep your generic /chat endpoint ----------

@app.route('/chat', methods=['POST'])
def chat():
    """Generic raw prompt chat, if you still want it."""
    try:
        data = request.json or {}
        prompt = data.get('prompt', '').strip()

        if not prompt:
            return jsonify({'success': False, 'error': 'No prompt provided'}), 400

        result = generate_with_fallback(prompt)
        status_code = 200 if result.get('success') else 500
        return jsonify(result), status_code

    except Exception as e:
        error_msg = str(e)
        print(f"[ERROR] /chat error: {error_msg}")
        return jsonify({'success': False, 'error': error_msg}), 500


# ---------- MAIN: consultation endpoint for your reports ----------

# This is the enhanced SYSTEM PROMPT you asked for:
CONSULT_SYSTEM_PROMPT = """
You are *DermaConsult AI*, a professional virtual medical consultant that helps users understand
skin-lesion analysis reports generated by an automated image-analysis system.

Your role and behavior:
- You act like a calm, polite, and professional consultant.
- You understand the technical report, but you *never* speak in the same technical language.
- You translate everything into clear, simple, layman-friendly explanations.
- You always speak as if you are talking to a non-medical person (unless explicitly told the audience is a doctor).

Scope (very important):
- You ONLY discuss medical/dermatology topics related to the provided report or the user’s skin-health questions.
- If the user asks about anything outside this domain (e.g., politics, coding, exams, general life advice),
  you briefly say that you are only for medical/skin consultation and politely redirect them back to the report or skin health.
- You do NOT answer questions unrelated to medical consulting.

Safety and limitations:
- You are NOT a doctor and NOT a replacement for a dermatologist.
- You NEVER give a definitive diagnosis (e.g., "This is definitely cancer" or "You are safe").
- You NEVER prescribe medications, dosages, or specific treatments.
- You NEVER tell the user to ignore symptoms or skip seeing a doctor.
- You ALWAYS encourage the user to consult a dermatologist or qualified medical professional,
  especially if the report suggests any risk or if the user is worried.

How to handle the report:
- The report may contain:
  - A DIAGNOSIS label and confidence score.
  - A list of dermoscopic concepts with scores.
  - Concept influence or other technical sections.
- You:
  - Read and understand the DIAGNOSIS and confidence.
  - Use it only as an indication of possible risk, never as a final answer.
  - Identify which concepts seem important and explain them in plain language
    (for example, explain what "pigment network", "streaks", or "vascular structures" mean,
     but keep it high-level and not too scary).
  - Always mention uncertainty: that AI can be wrong, and images alone are not enough.

Style of responses:
- Use friendly, respectful tone. Avoid sounding like a robot.
- Prefer short paragraphs and bullet points where helpful.
- Explain technical words immediately in simple terms.
  Example:
    - Instead of "There is an irregular pigment network",
      say "The image shows an uneven pattern of skin color, which doctors sometimes look at when checking for risky moles."
- Focus on what the user might *want to know*:
  - "What does this report mean in simple words?"
  - "How serious might this be?"
  - "What should I do next?"
- NEVER copy the report text back as-is. Always rephrase into layman language.

Out-of-scope questions:
- If the user asks anything like:
  - "Write code", "Help with my exam", "Tell me a joke", "Explain politics", etc.
  → You respond with something like:
    "I’m designed only for helping you understand skin and health reports. I can’t help with that topic.
     Is there anything about your report or skin health you’d like to ask?"
- Stay polite and firm about this limitation.

Disclaimer (always implied, often explicit at the end):
- Remind the user that:
  - The report comes from an AI system and may be wrong.
  - You are just explaining and not diagnosing.
  - They should see a dermatologist or doctor for proper evaluation.
"""


def build_consult_prompt(report_text: str,
                         user_message: str,
                         history=None,
                         audience: str = "patient") -> str:
    """
    Build the full prompt string sent to Gemini.
    history: optional list of {"role": "user"/"assistant", "content": "..."} for basic chat memory.
    """

    # Audience instructions (optional, you can expand later)
    if audience.lower() == "doctor":
        audience_block = (
            "Audience: the user is a clinician. You may use some medical terms, but still be clear and structured.\n"
        )
    else:
        audience_block = (
            "Audience: the user is a layperson with no medical background. Use very simple language.\n"
        )

    # Build simple history text (optional)
    history = history or []
    history_lines = []
    for turn in history:
        role = turn.get("role", "user").strip().lower()
        content = (turn.get("content") or "").strip()
        if not content:
            continue
        if role == "assistant":
            history_lines.append(f"Assistant: {content}")
        else:
            history_lines.append(f"User: {content}")
    history_text = "\n".join(history_lines) if history_lines else "None yet."

    prompt = f"""{CONSULT_SYSTEM_PROMPT}

{audience_block}

Below is the full analysis report produced by the automated system:

=== REPORT BEGIN ===
{report_text}
=== REPORT END ===

Conversation so far:
{history_text}

The user has now asked:
User: {user_message}

Your task:
1. Answer ONLY as DermaConsult AI, following all rules above.
2. Explain the report and answer the user’s question in simple, layman terms.
3. Stay strictly in the domain of skin/health consultation related to this report.
4. Emphasize uncertainty and advise seeing a dermatologist or doctor.
5. If the question is outside your domain, politely refuse and redirect to skin/report topics.

Assistant:"""

    return prompt


@app.route('/consult_report', methods=['POST'])
def consult_report():
    """
    POST /consult_report

    JSON body example:
    {
        "report_text": "<text from your old model>",
        "user_message": "Can you explain this in simple language?",
        "audience": "patient",   // or "doctor" (optional)
        "history": [
            {"role": "user", "content": "Earlier question..."},
            {"role": "assistant", "content": "Earlier answer..."}
        ]
    }
    """
    try:
        data = request.json or {}

        report_text = (data.get('report_text') or "").strip()
        user_message = (data.get('user_message') or "").strip()
        audience = (data.get('audience') or "patient").strip()
        history = data.get('history') or []

        if not report_text:
            return jsonify({'success': False, 'error': 'report_text is required'}), 400
        if not user_message:
            user_message = "Please explain this report in simple language for me."

        print("[DEBUG] /consult_report called")
        print(f"[DEBUG] Audience: {audience}")
        print(f"[DEBUG] User message: {user_message[:80]}...")

        full_prompt = build_consult_prompt(
            report_text=report_text,
            user_message=user_message,
            history=history,
            audience=audience
        )

        result = generate_with_fallback(full_prompt)
        status_code = 200 if result.get('success') else 500
        return jsonify(result), status_code

    except Exception as e:
        error_msg = str(e)
        print(f"[ERROR] /consult_report error: {error_msg}")
        return jsonify({'success': False, 'error': error_msg}), 500


if __name__ == '__main__':
    print("=" * 60)
    print("Gemini Consultation Backend Starting...")
    print("=" * 60)
    print(f"API Key configured (hardcoded): {'Yes' if GEMINI_API_KEY else 'No'}")
    print("Server running on: http://localhost:5000")
    print("Endpoints:")
    print("  - GET  /health          : Health check")
    print("  - POST /chat            : Generic chat (optional)")
    print("  - POST /consult_report  : Report-based consultation")
    print("=" * 60)
    app.run(host='0.0.0.0', port=5000, debug=False)
